{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2caIWCoop7IkV55M0gP65",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blancavazquez/diplomado_IA/blob/main/notebooks/Tema03/ResNet_dogs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Módulo 11: Introducción a las redes neuronales\n",
        "## Tema 3: Redes convolucionales\n",
        "\n",
        "\n",
        "El objetivo de esta libreta es construir una red convolucional para clasificación multiclase. En esta libreta aprenderemos:\n",
        "\n",
        "* Aumentado de datos con pytorch\n",
        "* Uso de la clase dataloader en pytorch\n",
        "* Cargar los pesos de modelos pre-entrenados.\n",
        "\n",
        "\n",
        "En esta libreta, se usarán imágenes de la base de datos de: [Stanford Dogs Dataset](http://vision.stanford.edu/aditya86/ImageNetDogs/main.html)"
      ],
      "metadata": {
        "id": "vTMjG-EIl3yG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Instalación de bibliotecas necesarias."
      ],
      "metadata": {
        "id": "TGN42entcwRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Montaje de drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "V_IL5v8wnqIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycm==4.0\n",
        "!pip install torchvision\n",
        "!pip install torch\n",
        "!pip install pretrainedmodels\n",
        "!pip install torchcam"
      ],
      "metadata": {
        "id": "TFtdGanQquxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Carga de bibliotecas\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import warnings\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from pycm import ConfusionMatrix\n",
        "from skimage.color import rgb2gray\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision.transforms import v2\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "warnings.filterwarnings(\"ignore\")  # avoid printing out absolute paths"
      ],
      "metadata": {
        "id": "LbXxmr3mqQBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"************** Configuración de hiperparámetros ***********\"\"\"\n",
        "lr = 0.001\n",
        "epochs = 5 #1\n",
        "classes = 3\n",
        "patience = 10\n",
        "batch_size = 32 #16\n",
        "momentum = 0.9\n",
        "image_resize = 256 #128\n",
        "retrained_model = \"resnet18\"\n",
        "filename = \"resnet18\"\n",
        "path = \"/content/drive/MyDrive/Colab Notebooks/2024_DiplomadoIA/Data/bd_dogs/\"\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "clases=['Collie','Labrador_retriever','Shih_Tzu']\n",
        "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Device: \", device)"
      ],
      "metadata": {
        "id": "BNU38yLYqlQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Función para visualizar imágenes\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "9kjgyZYvqybl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 1: Preprocesamiento de datos"
      ],
      "metadata": {
        "id": "JxlzMU5jdCK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(path):\n",
        "    print(\"\\n\\n ****** Pre-processing data ******\")\n",
        "    train_transform = v2.Compose([v2.RandomResizedCrop((image_resize,image_resize),antialias=True), #224, 224\n",
        "                                  v2.RandomHorizontalFlip(p=0.5),\n",
        "                                  v2.Grayscale(),\n",
        "                                  v2.ToTensor(),\n",
        "                                  v2.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "    val_transform = v2.Compose([v2.Resize((image_resize,image_resize)),\n",
        "                                v2.CenterCrop(image_resize),\n",
        "                                v2.Grayscale(),\n",
        "                                v2.ToTensor(),\n",
        "                                v2.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "    test_transform = v2.Compose([v2.Resize((image_resize,image_resize)),\n",
        "                                v2.ToTensor(),\n",
        "                                v2.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
        "    print(\"\\n*Loading data\")\n",
        "    train_dataset = datasets.ImageFolder(root=path+\"train/\",transform=train_transform)\n",
        "    val_dataset = datasets.ImageFolder(root=path+\"val/\",transform=val_transform)\n",
        "    test_dataset = datasets.ImageFolder(root=path+\"test/\",transform=test_transform)\n",
        "    print(\"Size train_dataset: \", len(train_dataset))\n",
        "    print(\"Size val_dataset: \", len(val_dataset))\n",
        "    print(\"Size test_dataset: \", len(test_dataset))\n",
        "\n",
        "    print(\"\\n*Loading dataloaders\")\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "    return train_loader, val_loader,test_loader, len(train_dataset), len(val_dataset)"
      ],
      "metadata": {
        "id": "wQdije3OrNW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopper:\n",
        "    def __init__(self, patience=1, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.min_validation_loss = float('inf')\n",
        "\n",
        "    def early_stop(self, validation_loss):\n",
        "        if validation_loss < self.min_validation_loss:\n",
        "            self.min_validation_loss = validation_loss\n",
        "            self.counter = 0\n",
        "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "def save_model(epochs, model, optimizer, criterion):\n",
        "    \"\"\"\n",
        "    function for saving model\n",
        "    \"\"\"\n",
        "    #Guardar el mejor modelo\n",
        "    if not os.path.exists('modelos'):\n",
        "      os.mkdir('modelos')\n",
        "\n",
        "    torch.save({\n",
        "                'epoch': epochs,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': criterion,\n",
        "                }, 'modelos/cnn.pth')\n",
        "\n",
        "def plotting_loss(train_acc, valid_acc, train_loss, valid_loss, filename):\n",
        "    \"\"\"\n",
        "    Function for plotting performance during the training\n",
        "    \"\"\"\n",
        "    # accuracy plots\n",
        "    fig = plt.figure(figsize=(12,7)) #x,y\n",
        "    plt.subplots_adjust(wspace=0.3,hspace=0.4)\n",
        "\n",
        "    #Plotting: Accuracy\n",
        "    ax1 = plt.subplot(1, 2, 1)\n",
        "    ax1.plot(train_loss, label =\"Train\", color = \"red\")\n",
        "    ax1.plot(valid_loss, label =\"Val\", color = \"blue\")\n",
        "    ax1.grid(True, linestyle='-', linewidth=0.4)\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.legend()\n",
        "    ax1.set_title('Training loss',fontsize=10)\n",
        "\n",
        "    #Plotting: Loss\n",
        "    ax2 = plt.subplot(1, 2, 2)\n",
        "    ax2.plot(train_acc, label =\"Train\", color = \"red\")\n",
        "    ax2.plot(valid_acc, label =\"Val\", color = \"blue\")\n",
        "    ax2.grid(True, linestyle='-', linewidth=0.4)\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Accuracy %')\n",
        "    ax2.set_ylim(0,1)\n",
        "    ax2.legend()\n",
        "    ax2.set_title('Overall accuracy',fontsize=10)\n",
        "\n",
        "def compute_metrics(y_true, y_pred):\n",
        "    cm = ConfusionMatrix(y_true, y_pred, digit=2)\n",
        "    print(cm)\n",
        "    Accuracy_overall = cm.overall_stat['F1 Macro']\n",
        "    f1 = cm.overall_stat['Overall ACC']\n",
        "    cm.plot(cmap=plt.cm.Reds, number_label=True, plot_lib=\"seaborn\") #normalized=True\n",
        "    print(f\"F1 score: {f1:.3f}\")\n",
        "    print(\"Accuracy_overall: \", np.round(Accuracy_overall* 100,2), \"%\")\n",
        "\n",
        "def train(model, trainloader, optimizer, scheduler,criterion, device, num_images_train):\n",
        "    \"\"\"\n",
        "    Función para entrenar el clasificador multiclase\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    acc = 0\n",
        "    counter = 0\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "\n",
        "    for i, data in tqdm(enumerate(trainloader), total=len(trainloader)):\n",
        "        counter += 1\n",
        "        image, labels = data\n",
        "        image = image.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        prediction = model(image) # forward pass\n",
        "        _, preds = torch.max(prediction, 1)\n",
        "        loss = criterion(prediction, labels)\n",
        "        loss.backward() # backpropagation\n",
        "        optimizer.step() # update the optimizer parameters\n",
        "        running_loss += loss.item() * image.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data) #Cuenta el número de imágenes predichas correctamente\n",
        "        scheduler.step()\n",
        "    epoch_loss = running_loss / num_images_train\n",
        "    epoch_acc = running_corrects / num_images_train\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "def validate(model, testloader, criterion, device, num_images_val):\n",
        "    \"\"\"\n",
        "    Función para validar el clasificador multiclase\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    val_accuracy = 0\n",
        "    counter = 0\n",
        "    running_loss_val = 0.0\n",
        "    running_corrects_val = 0\n",
        "    with torch.no_grad():\n",
        "        for i, data in tqdm(enumerate(testloader), total=len(testloader)):\n",
        "            counter += 1\n",
        "            image, labels = data\n",
        "            labels = labels.to(device)\n",
        "            image = image.to(device)\n",
        "            outputs = model(image) # forward pass\n",
        "            loss = criterion(outputs, labels)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            running_loss_val += loss.item() * image.size(0)\n",
        "            running_corrects_val += torch.sum(preds == labels.data) #Cuenta el número de imágenes predichas correctamente\n",
        "\n",
        "    val_loss = running_loss_val / num_images_val\n",
        "    val_accuracy = running_corrects_val.double() / num_images_val\n",
        "    return val_loss, val_accuracy\n",
        "\n",
        "def inference(model, data_loader):\n",
        "    list_ytrue, list_ypred = [], []\n",
        "    model.eval()\n",
        "    i = 0\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(data_loader):\n",
        "            print(\"i : \", i)\n",
        "            image, label_true = data #target_in [16, 3, 224, 224]\n",
        "            label_pred = model(image.to(device))\n",
        "            pred_argmax = torch.max(label_pred, 1) #argmax\n",
        "            list_ytrue.extend(label_true.detach().cpu().numpy())\n",
        "            list_ypred.extend((pred_argmax.indices).detach().cpu().numpy())\n",
        "            i=i+1\n",
        "    return list_ytrue, list_ypred\n"
      ],
      "metadata": {
        "id": "2BcGoso6nn9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 2: Carga de datos\n",
        "\n",
        "Previamente se definieron las funciones para la carga de las imágenes."
      ],
      "metadata": {
        "id": "yVCK6oundLsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\n ****** Loading dataloaders ******\")\n",
        "train_loader, val_loader,test_loader, num_images_train, num_images_val = preprocessing(path)"
      ],
      "metadata": {
        "id": "vKUihlUfufSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\n ****** Visualizando una muestra de las imágenes ******\")\n",
        "inputs, classes = next(iter(train_loader)) # Se consigue un lote de las imágenes\n",
        "out = torchvision.utils.make_grid(inputs) # Se construye un grid para visualizar\n",
        "imshow(out, title=[clases[x] for x in classes])"
      ],
      "metadata": {
        "id": "xnwr9FTfuiml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 3: definición de la arquitectura"
      ],
      "metadata": {
        "id": "Z2y_fcTWdlpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\n ****** Defining ResNet model ******\")\n",
        "import torch.nn as nn\n",
        "import pretrainedmodels as pm\n",
        "model = pm.__dict__[retrained_model](pretrained='imagenet').to(device)\n",
        "model.avg_pool = nn.AdaptiveAvgPool2d(1).to(device)\n",
        "model.last_linear = nn.Sequential(nn.BatchNorm1d(512), #2048\n",
        "                                  nn.Dropout(p=0.25),\n",
        "                                  nn.Linear(in_features=512, out_features=256), #2048\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.BatchNorm1d(256, eps=1e-05, momentum=0.1), #2048\n",
        "                                  nn.Dropout(p=0.5),\n",
        "                                  nn.Linear(in_features=256, out_features=3)).to(device) #2048 #CLASIFICADOR\n",
        "\n",
        "print(\"*Total de parámetros\")\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"{total_params:,} total parameters.\")\n",
        "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"{total_trainable_params:,} training parameters.\")"
      ],
      "metadata": {
        "id": "WnhdkqltvJ9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento"
      ],
      "metadata": {
        "id": "HHM4Gt6xdyG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\n ****** Training ******\")\n",
        "train_loss, valid_loss = [], []\n",
        "train_acc, valid_acc = [], []\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "early_stopper = EarlyStopper(patience=patience, min_delta=10)\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print('-' * 89)\n",
        "    print(f\"[INFO]: Epoch {epoch+1} of {epochs}\")\n",
        "    train_epoch_loss, train_epoch_acc = train(model, train_loader, optimizer, exp_lr_scheduler,criterion, device, num_images_train)\n",
        "    valid_epoch_loss, valid_epoch_acc = validate(model, val_loader,  criterion, device, num_images_val)\n",
        "    train_loss.append(train_epoch_loss)\n",
        "    valid_loss.append(valid_epoch_loss)\n",
        "    train_acc.append(train_epoch_acc.detach().cpu().numpy())\n",
        "    valid_acc.append(valid_epoch_acc.detach().cpu().numpy())\n",
        "    print(f\"Training loss: {np.mean(train_epoch_loss):.3f}, training acc: {train_epoch_acc:.3f}\")\n",
        "    print(f\"Validation loss: {valid_epoch_loss:.3f}, validation acc: {valid_epoch_acc:.3f}\")\n",
        "    print('-'*89)\n",
        "\n",
        "    if valid_epoch_acc > best_acc:\n",
        "        best_acc = valid_epoch_acc\n",
        "\n",
        "    if early_stopper.early_stop(valid_epoch_loss):\n",
        "        break\n",
        "    time.sleep(5)\n",
        "\n",
        "print(f'Best val Acc: {best_acc:4f}')\n",
        "save_model(epochs, model, optimizer, criterion)\n",
        "print('* Training complete')"
      ],
      "metadata": {
        "id": "fDOK7MtIrVJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\n ****** Plotting loss ******\")\n",
        "plotting_loss(train_acc, valid_acc, train_loss, valid_loss, filename)"
      ],
      "metadata": {
        "id": "LEcVjOCHSkJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\n ****** Inference ******\")\n",
        "y_true, y_pred = inference(model, test_loader)\n",
        "print(\"list_ytrue: \", y_true)\n",
        "print(\"list_ypred: \", y_pred)"
      ],
      "metadata": {
        "id": "GDEu4I9ES06J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\n ****** Compute metrics ******\")\n",
        "compute_metrics(y_true, y_pred)"
      ],
      "metadata": {
        "id": "ffZjMHhXajoD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}