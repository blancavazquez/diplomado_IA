{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6qkmTOK8lI+BeZkKAf8Ol",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blancavazquez/diplomado_IA/blob/main/notebooks/Tema_02/Dropout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Módulo 11: Introducción a las redes neuronales\n",
        "# Tema 2: Redes densas\n",
        "## Sobreajuste y regularización\n",
        "\n",
        "El objetivo de esta libreta es construir una red neuronal densa sencilla para clasificar imágenes. En particular, en esta red se analizará la presencia de capas de dropout como estrategia de regularización. Para esti se crearán dos redes, una con capas de droput y una sin droput. El objetivo es graficar la pérdida durante el entrenamiento y observar las diferencias.\n",
        "\n",
        "En esta libreta se usarán los datos de [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html). El conjunto de datos CIFAR-10 consta de 60000 imágenes en color de 32x32 en 10 clases, con 6000 imágenes por clase. Hay 50.000 imágenes de entrenamiento y 10.000 imágenes de prueba."
      ],
      "metadata": {
        "id": "rqSyPKKl2Rq_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exXuZAYP2Pre"
      },
      "outputs": [],
      "source": [
        "!pip install wandb -qU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightning"
      ],
      "metadata": {
        "id": "oNPpxB4H-XbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 1: Carga de bibliotecas"
      ],
      "metadata": {
        "id": "ux8GgY5XFKtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torch import nn\n",
        "import lightning.pytorch as pl\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from pytorch_lightning.loggers.csv_logs import CSVLogger"
      ],
      "metadata": {
        "id": "yZqJWJYL3Dte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Biblioteca para visualizar la pérdida durante el entrenamiento\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "Eg6UV28O3A7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "YfXYUTqu3FV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 2: Carga de datos"
      ],
      "metadata": {
        "id": "LTdlbT6p-bW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Función para transformar las imágenes a tensor y normalizándolas-\n",
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
        "\n",
        "#Descarga y carga de datos\n",
        "batch_size = 32\n",
        "trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "#Generando los cargadores de datos\n",
        "trainset = torch.utils.data.Subset(trainset, np.random.choice(len(trainset), 2500, replace=False))\n",
        "testset = torch.utils.data.Subset(testset, np.random.choice(len(testset), 500, replace=False))\n",
        "print(\"train_subset: \", len(trainset), \"test_subset: \", len(testset))\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "CLASS_NAMES = (\"plane\", \"car\", \"bird\", \"cat\",\n",
        "               \"deer\", \"dog\", \"frog\", \"horse\",\n",
        "               \"ship\", \"truck\")"
      ],
      "metadata": {
        "id": "J5NtmR2-BvIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizamos algunas imágenes del conjunto de datos CIFAR10"
      ],
      "metadata": {
        "id": "IhKHU5cAGgdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_batch(image_batch, label_batch):\n",
        "  #Función para visualizar algunas imágenes de CIFA10\n",
        "  plt.figure(figsize=(10,10))\n",
        "  for n in range(25):\n",
        "      ax = plt.subplot(5,5,n+1)\n",
        "      img = image_batch[n] / 2 + 0.5     # unnormalize\n",
        "      img = img.numpy()\n",
        "      plt.imshow(np.transpose(img, (1, 2, 0)))\n",
        "      plt.title(CLASS_NAMES[label_batch[n]])\n",
        "      plt.axis(\"off\")\n",
        "\n",
        "sample_images, sample_labels = next(iter(trainloader))\n",
        "show_batch(sample_images, sample_labels)"
      ],
      "metadata": {
        "id": "Puy3flRyCKKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 3: Definición de la arquitectura del modelo\n",
        "\n",
        "Se construye una arquitectura simple: con 3 capas.\n",
        "* La primera capa recibe la imagen de entra (3 x 32 x 32) y la aplana. Esta capa está compuesta de 128 neuronas.\n",
        "* La segunda capa tiene 128 neuronas de entrada y 64 de salida\n",
        "* La tercera capa es la de salida, con 10 neuronas (una por cada clase)"
      ],
      "metadata": {
        "id": "s7mwdPQA-hPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class lineal_net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(lineal_net, self).__init__()\n",
        "        self.fc1 = nn.Sequential(nn.Linear(3 * 32 * 32, 128), nn.Dropout(p=0.2)) # Flatten the 32x32 RGB images\n",
        "        self.fc2 = nn.Linear(128, 64) #capa intermedia\n",
        "        self.fc3 = nn.Linear(64, 10)  # Capa de salida con 10 clases\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 3 * 32 * 32)  # Aplanado de las imágenes de entrada\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "cd3xiyoM-koU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 4: Entrenamiento del modelo"
      ],
      "metadata": {
        "id": "yBPKtrle-nsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Lit_lineal_net(pl.LightningModule):\n",
        "  def __init__(self, model):\n",
        "    super().__init__()\n",
        "    self.model = model\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    x, y = batch\n",
        "    # print(y)\n",
        "    out = self.model(x)\n",
        "    # print(out)\n",
        "    loss = criterion(out, y)\n",
        "    preds = torch.argmax(out, dim=1)\n",
        "    accuracy = torch.sum(preds == y).item() / y.size(0)\n",
        "\n",
        "    self.log('train_loss', loss,  on_epoch=True)  # Log training loss\n",
        "    self.log('train_accuracy', accuracy,  on_epoch=True)\n",
        "    wandb.log({\"Train Loss\": loss, \"Train Accuracy\": accuracy})\n",
        "    return loss\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = torch.optim.SGD(self.model.parameters(), lr=0.001, momentum=0.9)\n",
        "    return optimizer"
      ],
      "metadata": {
        "id": "tYm9iF1a-q5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Función de pérdida\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#Instanciando el modelo\n",
        "model = Lit_lineal_net(lineal_net())\n",
        "\n",
        "#Variables para la visualización\n",
        "wandb.init(project=\"dropout\")\n",
        "wandb.watch(model, log=\"all\")\n",
        "\n",
        "#Entrenamiento de la red\n",
        "trainer = pl.Trainer(max_epochs=100,  logger=CSVLogger(\"logs\"))\n",
        "trainer.fit(model = model, train_dataloaders=trainloader)\n",
        "\n",
        "print(\"Finished Training\")\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "sYV6JYRH-u-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "metrics = pd.read_csv(f\"{trainer.logger.log_dir}/metrics.csv\")\n",
        "del metrics[\"step\"]\n",
        "metrics.set_index(\"epoch\", inplace=True)\n",
        "sn.relplot(data=metrics, kind=\"line\")"
      ],
      "metadata": {
        "id": "pEgeOvZK-6tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio\n",
        "Usando la arquitectura anterior, evalúa el rendimiento de la red cuando:\n",
        "\n",
        "1. Cambias la tasa de dropout.\n",
        "2. Añades varias capas de droput\n",
        "3. Eliminar la capa de droput\n",
        "\n",
        "¿Observas alguna diferencia? ¿Mejora la exactitud del modelo?, ¿Qué pasa con la pérdida?"
      ],
      "metadata": {
        "id": "wk17TTDzJ3Vt"
      }
    }
  ]
}